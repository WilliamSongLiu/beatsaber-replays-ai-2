{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "seed = 6969\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import pathlib\n",
    "replays_dir = pathlib.Path(\"replays\")\n",
    "\n",
    "import os\n",
    "model_dir = \"model\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_segment_size = 12\n",
    "post_segment_size = 12\n",
    "prediction_size = 1\n",
    "segment_size = pre_segment_size + post_segment_size + prediction_size\n",
    "\n",
    "note_size = 47\n",
    "\n",
    "input_shape = (segment_size, note_size)\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaderboard_id_replays(leaderboard_id):\n",
    "    replay_files = glob.glob(f\"{replays_dir}/{leaderboard_id}/*.npy\")\n",
    "    return leaderboard_id, replay_files\n",
    "\n",
    "\n",
    "def get_leaderboard_replays():\n",
    "    leaderboard_ids = [d for d in replays_dir.iterdir() if d.is_dir()]\n",
    "    random.shuffle(leaderboard_ids)\n",
    "    val_leaderboard_ids = leaderboard_ids[: int(len(leaderboard_ids) * 0.2)]\n",
    "\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for leaderboard_id in leaderboard_ids:\n",
    "        replay_files = glob.glob(f\"{leaderboard_id}/*.npy\")\n",
    "\n",
    "        if leaderboard_id in val_leaderboard_ids:\n",
    "            val_data.append((leaderboard_id, replay_files))\n",
    "        else:\n",
    "            train_data.append((leaderboard_id, replay_files))\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def get_replay_notes(replay, njs):\n",
    "    notes = []\n",
    "\n",
    "    prev_red_note_time = 0\n",
    "    prev_blue_note_time = 0\n",
    "\n",
    "    for note_info, score, note_time in sorted(replay, key=lambda item: item[2]):\n",
    "        color = note_info[-2]\n",
    "\n",
    "        delta_to_red = note_time - prev_red_note_time\n",
    "        delta_to_blue = note_time - prev_blue_note_time\n",
    "\n",
    "        if color == \"0\":\n",
    "            prev_red_note_time = note_time\n",
    "            note = preprocess_note(score, delta_to_red, delta_to_blue, note_info, njs)\n",
    "            notes.append(note)\n",
    "        if color == \"1\":\n",
    "            prev_blue_note_time = note_time\n",
    "            note = preprocess_note(score, delta_to_blue, delta_to_red, note_info, njs)\n",
    "            notes.append(note)\n",
    "\n",
    "    return notes\n",
    "\n",
    "\n",
    "def preprocess_note(score, delta_to_same_color, delta_to_opposite_color, note_info, njs):\n",
    "    # delta_to_same_color_short = max(0, 0.5 - delta_to_same_color)*2\n",
    "    # delta_to_same_color_long = max(0, 2 - delta_to_same_color)/2\n",
    "    # delta_to_opposite_color_short = max(0, 0.5 - delta_to_opposite_color)*2\n",
    "    # delta_to_opposite_color_long = max(0, 2 - delta_to_opposite_color)/2\n",
    "\n",
    "    col_number = int(note_info[1])\n",
    "    row_number = int(note_info[2])\n",
    "\n",
    "    direction_number = int(note_info[4])\n",
    "    color = int(note_info[3])\n",
    "\n",
    "    row_col_red = [0] * 4 * 3\n",
    "    direction_red = [0] * 10\n",
    "    row_col_blue = [0] * 4 * 3\n",
    "    direction_blue = [0] * 10\n",
    "    if color == 0:\n",
    "        row_col_red[col_number * 3 + row_number] = 1\n",
    "        direction_red[direction_number] = 1\n",
    "    if color == 1:\n",
    "        row_col_blue[col_number * 3 + row_number] = 1\n",
    "        direction_blue[direction_number] = 1\n",
    "\n",
    "    response = []\n",
    "    if color == 0:\n",
    "        response.extend(row_col_red)\n",
    "        response.extend(direction_red)\n",
    "        response.extend(row_col_blue)\n",
    "        response.extend(direction_blue)\n",
    "        # response.append(delta_to_same_color_short)\n",
    "        # response.append(delta_to_same_color_long)\n",
    "        # response.append(delta_to_opposite_color_short)\n",
    "        # response.append(delta_to_opposite_color_long)\n",
    "        response.append(delta_to_same_color)\n",
    "        response.append(delta_to_opposite_color)\n",
    "    if color == 1:\n",
    "        response.extend(row_col_blue)\n",
    "        response.extend(direction_blue)\n",
    "        response.extend(row_col_red)\n",
    "        response.extend(direction_red)\n",
    "        # response.append(delta_to_opposite_color_short)\n",
    "        # response.append(delta_to_opposite_color_long)\n",
    "        # response.append(delta_to_same_color_short)\n",
    "        # response.append(delta_to_same_color_long)\n",
    "        response.append(delta_to_opposite_color)\n",
    "        response.append(delta_to_same_color)\n",
    "    # response.append(njs / 30)\n",
    "    response.append(njs)\n",
    "    response.append(score)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_segments(notes):\n",
    "    # NOTE: using relative score can be good to find relative difficulty of the notes more fairly\n",
    "    # because good players will always get higher acc and worse players will do badly even on easy patterns\n",
    "\n",
    "    if len(notes) < prediction_size:\n",
    "        return ([], [])\n",
    "\n",
    "    segments = []\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate with a step size of prediction_size to achieve non-overlapping segments\n",
    "    for i in range(0, len(notes) - prediction_size + 1, prediction_size):\n",
    "        pre_slice = notes[max(0, i - pre_segment_size) : i]\n",
    "        pre_segment = [np.array(note[:-1]) for note in pre_slice]\n",
    "        if len(pre_segment) < pre_segment_size:\n",
    "            # Insert at start of pre_segment\n",
    "            pre_segment[0:0] = [\n",
    "                np.zeros(note_size, dtype=np.float32)\n",
    "                for _ in range(pre_segment_size - len(pre_segment))\n",
    "            ]\n",
    "\n",
    "        slice = notes[i : i + prediction_size]\n",
    "        segment = [np.array(note[:-1]) for note in slice]\n",
    "\n",
    "        post_slice = notes[\n",
    "            i + prediction_size : i + prediction_size + post_segment_size\n",
    "        ]\n",
    "        post_segment = [np.array(note[:-1]) for note in post_slice]\n",
    "        if len(post_segment) < post_segment_size:\n",
    "            post_segment.extend(\n",
    "                [\n",
    "                    np.zeros(note_size, dtype=np.float32)\n",
    "                    for _ in range(post_segment_size - len(post_segment))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # fix this pls\n",
    "        prediction = [note[-1] for note in slice]\n",
    "\n",
    "        final_segment = []\n",
    "        final_segment.extend(pre_segment)\n",
    "        final_segment.extend(segment)\n",
    "        final_segment.extend(post_segment)\n",
    "        segments.append(final_segment)\n",
    "\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return segments, predictions\n",
    "\n",
    "\n",
    "def to_id(value):\n",
    "    if int(value) < 30000:\n",
    "        return str(30000 + int(value))\n",
    "    return str(int(value))\n",
    "\n",
    "\n",
    "def preprocess_leaderboard_replays(leaderboard_replays):\n",
    "    note_data = {}\n",
    "    replays = []\n",
    "\n",
    "    # Load and sort each replay by note time\n",
    "    for leaderboard_replay in leaderboard_replays:\n",
    "        arr = np.load(leaderboard_replay)\n",
    "        sort_indices = np.argsort(arr[:, 2])\n",
    "        sorted_arr = arr[sort_indices]\n",
    "        replays.append(sorted_arr)\n",
    "\n",
    "    # Process each replay to aggregate note data\n",
    "    for replay in replays:\n",
    "        if len(note_data.values()) == 0:\n",
    "            for values in replay:\n",
    "                note_id_time_key = to_id(values[0]) + str(values[2] * 100)\n",
    "                note_data[note_id_time_key] = [to_id(values[0]), [values[1]], values[2], 1]\n",
    "        else:\n",
    "            for values in replay:\n",
    "                note_id_time_key = to_id(values[0]) + str(values[2] * 100)\n",
    "                if note_id_time_key in note_data:\n",
    "                    note_data[note_id_time_key][1].append(values[1])\n",
    "                    note_data[note_id_time_key][2] += values[2]\n",
    "                    note_data[note_id_time_key][3] += 1\n",
    "\n",
    "    # Filter and average note data\n",
    "    processed_notes = []\n",
    "    for values in note_data.values():\n",
    "        if values[3] < 8 or len(values[0]) > 5:\n",
    "            return ([], [])\n",
    "\n",
    "        acc_list = values[1]\n",
    "        acc_list.sort()\n",
    "        acc = sum(acc_list) / len(acc_list) if len(acc_list) > 0 else 0\n",
    "        processed_notes.append([values[0], acc, values[2] / values[3]])\n",
    "\n",
    "    # Generate segments from the processed notes\n",
    "    notes = get_replay_notes(processed_notes, float(leaderboard_replays[0].split(\"-\")[3].replace(\".npy\", \"\")))\n",
    "    return create_segments(notes)\n",
    "\n",
    "\n",
    "def generate_data(leaderboards_replays):\n",
    "    all_segments = []\n",
    "    all_scores = []\n",
    "\n",
    "    for (leaderboard_id, leaderboard_replays) in leaderboards_replays:\n",
    "        segments, scores = preprocess_leaderboard_replays(leaderboard_replays)\n",
    "        if len(segments) == 0:\n",
    "            continue\n",
    "\n",
    "        all_segments.extend(segments)\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "    return np.array(all_segments), np.array(all_scores)\n",
    "\n",
    "\n",
    "def clamp(num, lower, higher):\n",
    "    return min([max([num, lower]), higher])\n",
    "\n",
    "\n",
    "train_data, val_data = get_leaderboard_replays()\n",
    "test_data = val_data\n",
    "\n",
    "train_x, train_y = generate_data(train_data)\n",
    "val_x, val_y = generate_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model, layers\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "bidirectional_1 = layers.Bidirectional(layers.LSTM(units=12, return_sequences=True, activation=\"tanh\"), backward_layer=layers.LSTM(units=12, return_sequences=True, go_backwards=True, activation=\"tanh\"))(input_layer)\n",
    "bidirectional_2 = layers.Bidirectional(layers.LSTM(units=10, return_sequences=True, activation=\"tanh\"), backward_layer=layers.LSTM(units=10, return_sequences=True, go_backwards=True, activation=\"tanh\"))(bidirectional_1)\n",
    "\n",
    "# Concatenate the output of the second bidirectional LSTM layer with the input\n",
    "concatenate = layers.Concatenate()([bidirectional_2, input_layer])\n",
    "\n",
    "# Cropping1D layer\n",
    "cropping1d = layers.Cropping1D(cropping=(12, 12))(concatenate)  # Adjust the cropping as necessary\n",
    "\n",
    "# TimeDistributed layer with Dense layer inside\n",
    "time_distributed_1 = layers.TimeDistributed(layers.Dense(units=16, activation=\"relu\"))(cropping1d)\n",
    "\n",
    "# Another TimeDistributed layer with Dense layer inside\n",
    "time_distributed_2 = layers.TimeDistributed(layers.Dense(units=16, activation=\"relu\"))(time_distributed_1)\n",
    "\n",
    "# Final TimeDistributed layer with Dense layer for output\n",
    "time_distributed_3 = layers.TimeDistributed(layers.Dense(units=1, activation=\"linear\"))(time_distributed_2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=time_distributed_3)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(reduction=\"sum_over_batch_size\"),\n",
    "    metrics=['mse'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "global initial_epoch\n",
    "initial_epoch = 0\n",
    "class EpochCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global initial_epoch\n",
    "        initial_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=[tensorboard_callback, EpochCallback()],\n",
    "    batch_size=128,\n",
    "    epochs=initial_epoch + train_epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "\n",
    "model.save(f\"{model_dir}/model.keras\")\n",
    "\n",
    "spec = (tf.TensorSpec((None, segment_size, note_size), tf.float32, name=\"input_1\"),)\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=None, output_path=f\"{model_dir}/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def acc_to_percent(acc):\n",
    "\treturn (acc * 15 + 100) / 1.15\n",
    "\n",
    "test_maps = [\n",
    "\t[\"fc4c11\", \"Naughty little demon - Easy\"],\n",
    "\t[\"d90a11\", \"Watch Me Dance - Easy\"],\n",
    "\t[\"16abf91\", \"The Nights - Ex+\"],\n",
    "\t[\"2450491\", \"The Girl - Ex+\"],\n",
    "\t# [\"2c803x91\", \"ANOMALY - Ex+\"],\n",
    "\t[\"31fbd91\", \"Sequence Breaker - Ex+\"],\n",
    "\t[\"3963ex92\", \"heaven - One Saber\"],\n",
    "\t# [\"3838axxx92\", \"Lace It - One Saber\"],\n",
    "\t# [\"35062x92\", \"Spin Eternally - One Saber\"],\n",
    "]\n",
    "\n",
    "for leaderboard_id, map_name in test_maps:\n",
    "\ttest_x, test_y = generate_data([get_leaderboard_id_replays(leaderboard_id)])\n",
    "\ttest_pred = model(test_x)\n",
    "\n",
    "\treal_acc = []\n",
    "\tpredicted_acc = []\n",
    "\n",
    "\tfor map_y, map_pred in zip(test_y, test_pred):\n",
    "\t\tfor note_y, note_pred in zip(map_y, map_pred):\n",
    "\t\t\treal_acc.append(acc_to_percent(note_y))\n",
    "\t\t\tpredicted_acc.append(acc_to_percent(note_pred[0]))\n",
    "\n",
    "\toverall_real_acc = sum(real_acc)/len(real_acc)\n",
    "\toverall_predicted_acc = sum(predicted_acc)/len(predicted_acc)\n",
    "\tprint(f\"{map_name} - Real acc: {overall_real_acc} - Predicted acc: {overall_predicted_acc}\")\n",
    "\n",
    "\tplt.figure(figsize=(6, 4))\n",
    "\tplt.title(f\"{map_name} ({leaderboard_id})\")\n",
    "\n",
    "\treal_acc_smoothed = np.convolve(real_acc, np.ones(15)/15, mode=\"valid\")\n",
    "\tx_real = [i for i in range(len(real_acc_smoothed))]\n",
    "\tplt.plot(x_real, real_acc_smoothed, label=\"Real Acc\")\n",
    "\n",
    "\tpredicted_acc_smoothed = np.convolve(predicted_acc, np.ones(15)/15, mode=\"valid\")\n",
    "\tx_pred = [i for i in range(len(predicted_acc_smoothed))]\n",
    "\tplt.plot(x_pred, predicted_acc_smoothed, label=\"Predicted Acc\")\n",
    "\n",
    "\tplt.xlabel(\"Note #\")\n",
    "\tplt.ylabel(\"Acc\")\n",
    "\tplt.tick_params(axis=\"x\")\n",
    "\tplt.tick_params(axis=\"y\")\n",
    "\tplt.xlim(0, max(len(x_real), len(x_pred)))\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.tight_layout(pad=1.0, w_pad=0.5, h_pad=0.5)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for leaderboard_id, leaderboard_replays in test_data:\n",
    "    try:\n",
    "        curr, score = preprocess_leaderboard_replays(leaderboard_replays)\n",
    "\n",
    "        _predictions = model.predict(np.array(curr))\n",
    "\n",
    "        real_sum = 0\n",
    "        for prediction in score:\n",
    "            real_sum += prediction[0]\n",
    "\n",
    "        real_avg = real_sum / len(score)\n",
    "        real_percentage_score = (100 + real_avg * 15) / 115\n",
    "\n",
    "        prediction_sum = 0\n",
    "        for prediction in _predictions:\n",
    "            prediction_sum += prediction[0]\n",
    "\n",
    "        avg = prediction_sum / len(_predictions)\n",
    "        percentage_score = (100 + avg[0] * 15) / 115\n",
    "\n",
    "        predictions.append(\n",
    "            [\n",
    "                f\"https://beatleader.xyz/leaderboard/global/{leaderboard_id}\",\n",
    "                round(percentage_score, 5),\n",
    "                round(real_percentage_score, 5),\n",
    "                abs(round(real_percentage_score - percentage_score, 5)),\n",
    "            ]\n",
    "        )\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "with open(f\"{model_dir}/predictions.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = [\"LeaderboardId\", \"Prediction\", \"Expected\", \"Difference\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for prediction in predictions:\n",
    "        writer.writerow(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
