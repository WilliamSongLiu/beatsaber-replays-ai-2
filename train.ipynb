{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random\n",
    "import glob\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "seed = 6969\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import pathlib\n",
    "replays_dir = pathlib.Path(\"replays\")\n",
    "\n",
    "import os\n",
    "model_dir = \"model\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to overfit on a small sample to confirm the model is working\n",
    "mode = \"sample\"\n",
    "# Use full dataset\n",
    "# mode = \"full\"\n",
    "\n",
    "# Quiet Water - 7e8f11\n",
    "# Watch Me Dance! - d90a11\n",
    "# Sequence Breaker - 31fbd91\n",
    "# Atomic - 220f2xxx91\n",
    "# BREAKSH!T - 27e38x11\n",
    "sample_maps = [\"27e38x11\"]\n",
    "\n",
    "pre_segment_size = 12\n",
    "post_segment_size = 12\n",
    "prediction_size = 1\n",
    "segment_size = pre_segment_size + post_segment_size + prediction_size\n",
    "\n",
    "note_size = 47\n",
    "\n",
    "input_shape = (segment_size, note_size)\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replays_for_leaderboard(leaderboard_dir):\n",
    "    return glob.glob(f\"{replays_dir}/{leaderboard_dir}/*.npy\")\n",
    "\n",
    "\n",
    "def load_leaderboards():\n",
    "    # leaderboard_dir format: id-njs-name\n",
    "    # leaderboard format: (dir, id, njs, name, replays)\n",
    "\n",
    "    leaderboard_dirs = [d.name for d in replays_dir.iterdir() if d.is_dir()]\n",
    "    leaderboards = [[leaderboard_dir] + leaderboard_dir.split(\"-\") for leaderboard_dir in leaderboard_dirs]\n",
    "    for leaderboard in leaderboards:\n",
    "        leaderboard[2] = float(leaderboard[2])\n",
    "        leaderboard.append(get_replays_for_leaderboard(leaderboard[0]))\n",
    "    return leaderboards\n",
    "\n",
    "\n",
    "def split_leaderboards(leaderboards):\n",
    "    if mode == \"sample\":\n",
    "        # sampled_leaderboards = random.sample(leaderboards, sample_size)\n",
    "        sampled_leaderboards = [leaderboard for leaderboard in leaderboards if leaderboard[1] in sample_maps]\n",
    "        return sampled_leaderboards, sampled_leaderboards\n",
    "    else:\n",
    "        train_leaderboards, test_leaderboards = train_test_split(leaderboards, test_size=0.2)\n",
    "        return train_leaderboards, test_leaderboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replay_notes(replay, njs):\n",
    "\tnotes = []\n",
    "\n",
    "\tprev_red_note_time = 0\n",
    "\tprev_blue_note_time = 0\n",
    "\n",
    "\tfor note_info, accpercent, note_time in sorted(replay, key=lambda item: item[2]):\n",
    "\t\tcolor = note_info[-2]\n",
    "\n",
    "\t\tdelta_to_red = note_time - prev_red_note_time\n",
    "\t\tdelta_to_blue = note_time - prev_blue_note_time\n",
    "\n",
    "\t\tif color == \"0\":\n",
    "\t\t\tprev_red_note_time = note_time\n",
    "\t\t\tnote = preprocess_note(accpercent, delta_to_red, delta_to_blue, note_info, njs)\n",
    "\t\t\tnotes.append(note)\n",
    "\t\tif color == \"1\":\n",
    "\t\t\tprev_blue_note_time = note_time\n",
    "\t\t\tnote = preprocess_note(accpercent, delta_to_blue, delta_to_red, note_info, njs)\n",
    "\t\t\tnotes.append(note)\n",
    "\n",
    "\treturn notes\n",
    "\n",
    "\n",
    "def preprocess_note(accpercent, delta_to_same_color, delta_to_opposite_color, note_info, njs):\n",
    "\t# delta_to_same_color_short = max(0, 0.5 - delta_to_same_color)*2\n",
    "\t# delta_to_same_color_long = max(0, 2 - delta_to_same_color)/2\n",
    "\t# delta_to_opposite_color_short = max(0, 0.5 - delta_to_opposite_color)*2\n",
    "\t# delta_to_opposite_color_long = max(0, 2 - delta_to_opposite_color)/2\n",
    "\n",
    "\tcol_number = int(note_info[1])\n",
    "\trow_number = int(note_info[2])\n",
    "\n",
    "\tcolor = int(note_info[3])\n",
    "\tdirection_number = int(note_info[4])\n",
    "\n",
    "\trow_col_red = [0] * 4 * 3\n",
    "\tdirection_red = [0] * 10\n",
    "\trow_col_blue = [0] * 4 * 3\n",
    "\tdirection_blue = [0] * 10\n",
    "\tif color == 0:\n",
    "\t\trow_col_red[col_number * 3 + row_number] = 1\n",
    "\t\tdirection_red[direction_number] = 1\n",
    "\telif color == 1:\n",
    "\t\trow_col_blue[col_number * 3 + row_number] = 1\n",
    "\t\tdirection_blue[direction_number] = 1\n",
    "\n",
    "\tdelta_to_red = delta_to_same_color if color == 0 else delta_to_opposite_color\n",
    "\tdelta_to_blue = delta_to_same_color if color == 1 else delta_to_opposite_color\n",
    "\n",
    "\tresponse = []\n",
    "\tresponse.extend(row_col_red)\n",
    "\tresponse.extend(direction_red)\n",
    "\tresponse.extend(row_col_blue)\n",
    "\tresponse.extend(direction_blue)\n",
    "\tresponse.append(delta_to_red)\n",
    "\tresponse.append(delta_to_blue)\n",
    "\t# response.append(njs / 30)\n",
    "\tresponse.append(njs)\n",
    "\tresponse.append(accpercent)\n",
    "\n",
    "\treturn response\n",
    "\n",
    "\n",
    "def create_segments(notes):\n",
    "\t# NOTE: using relative score can be good to find relative difficulty of the notes more fairly\n",
    "\t# because good players will always get higher acc and worse players will do badly even on easy patterns\n",
    "\n",
    "\tif len(notes) < prediction_size:\n",
    "\t\treturn ([], [])\n",
    "\n",
    "\tsegments = []\n",
    "\taccpercents = []\n",
    "\n",
    "\t# Iterate with a step size of prediction_size to achieve non-overlapping segments\n",
    "\tfor i in range(0, len(notes) - prediction_size + 1, prediction_size):\n",
    "\t\t# note[:-1] is result from preprocess_note except the accpercent\n",
    "\n",
    "\t\tpre_slice = notes[max(0, i - pre_segment_size) : i]\n",
    "\t\tpre_segment = [np.array(note[:-1]) for note in pre_slice]\n",
    "\t\tif len(pre_segment) < pre_segment_size:\n",
    "\t\t\t# Insert zeros at start of pre_segment\n",
    "\t\t\tpre_segment[0:0] = [\n",
    "\t\t\t\tnp.zeros(note_size, dtype=np.float32)\n",
    "\t\t\t\tfor _ in range(pre_segment_size - len(pre_segment))\n",
    "\t\t\t]\n",
    "\n",
    "\t\tslice = notes[i : i + prediction_size]\n",
    "\t\tsegment = [np.array(note[:-1]) for note in slice]\n",
    "\n",
    "\t\tpost_slice = notes[\n",
    "\t\t\ti + prediction_size : i + prediction_size + post_segment_size\n",
    "\t\t]\n",
    "\t\tpost_segment = [np.array(note[:-1]) for note in post_slice]\n",
    "\t\tif len(post_segment) < post_segment_size:\n",
    "\t\t\t# Insert zeros at end of pre_segment\n",
    "\t\t\tpost_segment.extend([\n",
    "\t\t\t\tnp.zeros(note_size, dtype=np.float32)\n",
    "\t\t\t\tfor _ in range(post_segment_size - len(post_segment))\n",
    "\t\t\t])\n",
    "\n",
    "\t\t# ASK: What does this comment mean\n",
    "\t\t# fix this pls\n",
    "\t\tsegment_accpercents = [note[-1] for note in slice]\n",
    "\n",
    "\t\tfinal_segment = []\n",
    "\t\tfinal_segment.extend(pre_segment)\n",
    "\t\tfinal_segment.extend(segment)\n",
    "\t\tfinal_segment.extend(post_segment)\n",
    "\t\tsegments.append(final_segment)\n",
    "\n",
    "\t\taccpercents.append(segment_accpercents)\n",
    "\n",
    "\treturn segments, accpercents\n",
    "\n",
    "\n",
    "def to_id(value):\n",
    "\t# This is to accomodate V3 scoring somehow\n",
    "\t# id format: (scoring type + 2) * 10000 + line index * 1000 + note line layer * 100 + color * 10 + direction\n",
    "\tif int(value) < 30000:\n",
    "\t\t# print(f\"orig {int(value)}\")\n",
    "\t\treturn str(30000 + int(value))\n",
    "\treturn str(int(value))\n",
    "\n",
    "\n",
    "def preprocess_leaderboard_replays(leaderboard):\n",
    "\t# replay note format: (id, acc, spawn time)\n",
    "\t# note_data format: (id, [accs], total spawn time, num occurences)\n",
    "\t# processed_notes format: (id, avg acc, avg spawn time)\n",
    "\n",
    "\treplays = []\n",
    "\tnote_data = {}\n",
    "\n",
    "\t# Load and sort each replay by note time\n",
    "\tfor leaderboard_replay in leaderboard[4]:\n",
    "\t\tnotes = np.load(leaderboard_replay)\n",
    "\t\treplays.append(notes[np.argsort(notes[:, 2])])\n",
    "\n",
    "\t# Process each replay to aggregate note data\n",
    "\tfor replay in replays:\n",
    "\t\ti = 0\n",
    "\t\tfor note in replay:\n",
    "\t\t\t# PROBLEM: Times are different with different replays\n",
    "\t\t\t# If only to_id(note[0]) is used, then there is no differentiation between notes in same position/direction\n",
    "\t\t\t# Using i as a temporary solution, not sure if different replays have different note orderings\n",
    "\t\t\t# note_id_time_key = to_id(note[0]) + str(note[2] * 100)\n",
    "\n",
    "\t\t\t# Temporary solution: only accept normal non-V3 notes\n",
    "\t\t\tif to_id(note[0])[0] != \"3\":\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tnote_key = i\n",
    "\t\t\ti += 1\n",
    "\t\t\tif note_key not in note_data:\n",
    "\t\t\t\tnote_data[note_key] = [to_id(note[0]), [note[1]], note[2], 1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnote_data[note_key][1].append(note[1])\n",
    "\t\t\t\tnote_data[note_key][2] += note[2]\n",
    "\t\t\t\tnote_data[note_key][3] += 1\n",
    "\n",
    "\t# Filter and average note data\n",
    "\tprocessed_notes = []\n",
    "\tfor note in note_data.values():\n",
    "\t\t# If mapping extensions\n",
    "\t\tif len(note[0]) > 5:\n",
    "\t\t\treturn ([], [])\n",
    "\n",
    "\t\taccpercents = note[1]\n",
    "\t\tavg_accpercent = sum(accpercents) / len(accpercents)\n",
    "\t\tprocessed_notes.append([note[0], avg_accpercent, note[2] / note[3]])\n",
    "\n",
    "\t# Generate segments from the processed notes\n",
    "\tnotes = get_replay_notes(processed_notes, float(leaderboard[2]))\n",
    "\tsegments = create_segments(notes)\n",
    "\treturn segments\n",
    "\n",
    "\n",
    "def generate_data(leaderboards):\n",
    "\tall_segments = []\n",
    "\tall_accpercents = []\n",
    "\n",
    "\tfor leaderboard in leaderboards:\n",
    "\t\tsegments, accpercents = preprocess_leaderboard_replays(leaderboard)\n",
    "\t\tif len(segments) == 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tall_segments.extend(segments)\n",
    "\t\tall_accpercents.extend(accpercents)\n",
    "\n",
    "\treturn np.array(all_segments), np.array(all_accpercents)\n",
    "\n",
    "\n",
    "def check_replays_consistency(leaderboards):\n",
    "\tfor leaderboard in leaderboards:\n",
    "\t\treplays = []\n",
    "\n",
    "\t\t# Load and sort each replay by note time\n",
    "\t\tfor leaderboard_replay in leaderboard[4]:\n",
    "\t\t\tnotes = np.load(leaderboard_replay)\n",
    "\t\t\treplays.append(notes[np.argsort(notes[:, 2])])\n",
    "\n",
    "\t\t# Check if replay has multiple of same note ID and times\n",
    "\t\tfor i in range(len(replays)):\n",
    "\t\t\tnote_id_time_keys = {}\n",
    "\t\t\tfor j in range(len(replays[i])):\n",
    "\t\t\t\tnote = replays[i][j]\n",
    "\n",
    "\t\t\t\t# Temporary solution: only accept normal non-V3 notes\n",
    "\t\t\t\tif to_id(note[0])[0] != \"3\":\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tnote_id_time_key = to_id(note[0]) + str(note[2] * 100)\n",
    "\t\t\t\tif note_id_time_key not in note_id_time_keys:\n",
    "\t\t\t\t\tnote_id_time_keys[note_id_time_key] = []\n",
    "\t\t\t\tnote_id_time_keys[note_id_time_key].append(j)\n",
    "\n",
    "\t\t\tfor note_id_time_key, note_indices in note_id_time_keys.items():\n",
    "\t\t\t\tif len(note_indices) > 1:\n",
    "\t\t\t\t\tprint(f\"{leaderboard[3]} has {len(note_indices)} duplicate note in {leaderboard[4][i]}: {[replays[i][note_index] for note_index in note_indices]}\")\n",
    "\t\t\t\t\tpass\n",
    "\n",
    "\t\t# Check replays total note count that dont match others\n",
    "\t\t# mismatched_replays = 0\n",
    "\t\t# for i in range(1, len(replays)):\n",
    "\t\t# \tif len(replays[i]) != len(replays[0]):\n",
    "\t\t# \t\tprint(f\"{leaderboard[3]} replay length differs: {leaderboard[4][i]} {len(replays[i])} vs {leaderboard[4][0]} {len(replays[0])}\")\n",
    "\t\t# \t\tcontinue\n",
    "\t\t# \tmismatched_notes = 0\n",
    "\t\t# \tfor j in range(len(replays[i])):\n",
    "\t\t# \t\tif replays[i][j][0] != replays[0][j][0]:\n",
    "\t\t# \t\t\t# print(f\"{leaderboard[3]} mismatch on note {j}: {leaderboard[4][i]} {replays[i][j][0]} vs {leaderboard[4][0]} {replays[0][j][0]}\")\n",
    "\t\t# \t\t\tmismatched_notes += 1\n",
    "\t\t# \t# print(f\"{leaderboard[3]} mismatcheed notes: {mismatched_notes}\")\n",
    "\t\t# \tif mismatched_notes > 0:\n",
    "\t\t# \t\tmismatched_replays += 1\n",
    "\t\t# # print(f\"{leaderboard[3]} mismatcheed replays: {mismatched_replays}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accpercent_to_percent(accpercent):\n",
    "\treturn (accpercent * 15 + 100) / 115 * 100\n",
    "\n",
    "def examine_samples(leaderboards, model=None):\n",
    "\tfor examine_leaderboard_id in sample_maps:\n",
    "\t\texamine_leaderboard = next((leaderboard for leaderboard in leaderboards if leaderboard[1] == examine_leaderboard_id), None)\n",
    "\t\texamine_x, examine_y = generate_data([examine_leaderboard])\n",
    "\n",
    "\t\treal_percents = []\n",
    "\t\tfor note in examine_y:\n",
    "\t\t\treal_percents.append(accpercent_to_percent(note[0]))\n",
    "\n",
    "\t\tpred_percents = []\n",
    "\t\tif model is not None:\n",
    "\t\t\texamine_pred = model(examine_x)\n",
    "\t\t\tfor note in examine_pred:\n",
    "\t\t\t\tpred_percents.append(accpercent_to_percent(note.numpy()[0][0]))\n",
    "\n",
    "\t\toverall_real_percent = round(sum(real_percents) / len(real_percents), 2)\n",
    "\n",
    "\t\toverall_pred_percent = None\n",
    "\t\tif model is not None:\n",
    "\t\t\toverall_pred_percent = round(sum(pred_percents) / len(pred_percents), 2)\n",
    "\n",
    "\t\tplt.figure(figsize=(6, 4))\n",
    "\t\tplt.title(f\"{examine_leaderboard[3]} ({examine_leaderboard[1]}) - Real percent: {overall_real_percent}{f\" - Pred percent: {overall_pred_percent}\" if model is not None else \"\"}\")\n",
    "\n",
    "\t\tconvolution_size = round(len(real_percents) / 100) + 1\n",
    "\n",
    "\t\treal_percents_smoothed = np.convolve(real_percents, np.ones(convolution_size) / convolution_size, mode=\"valid\")\n",
    "\t\tx_real = [i for i in range(len(real_percents_smoothed))]\n",
    "\t\tplt.plot(x_real, real_percents_smoothed, label=\"Real Percent\")\n",
    "\n",
    "\t\tif model is not None:\n",
    "\t\t\tpred_percents_smoothed = np.convolve(pred_percents, np.ones(convolution_size) / convolution_size, mode=\"valid\")\n",
    "\t\t\tx_pred = [i for i in range(len(pred_percents_smoothed))]\n",
    "\t\t\tplt.plot(x_pred, pred_percents_smoothed, label=\"Pred Percent\")\n",
    "\n",
    "\t\tplt.xlabel(\"Note #\")\n",
    "\t\tplt.ylabel(\"Percent\")\n",
    "\t\tplt.tick_params(axis=\"x\")\n",
    "\t\tplt.tick_params(axis=\"y\")\n",
    "\t\tplt.xlim(0, len(x_real) - 1)\n",
    "\t\tplt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\t\tplt.legend()\n",
    "\n",
    "\t\tplt.tight_layout(pad=1.0, w_pad=0.5, h_pad=0.5)\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboards = load_leaderboards()\n",
    "train_leaderboards, test_leaderboards = split_leaderboards(leaderboards)\n",
    "\n",
    "train_x, train_y = generate_data(train_leaderboards)\n",
    "test_x, test_y = generate_data(test_leaderboards)\n",
    "\n",
    "check_replays_consistency(leaderboards)\n",
    "examine_samples(leaderboards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model, layers\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "bidirectional_1 = layers.Bidirectional(layers.LSTM(units=12, return_sequences=True, activation=\"tanh\"), backward_layer=layers.LSTM(units=12, return_sequences=True, go_backwards=True, activation=\"tanh\"))(input_layer)\n",
    "bidirectional_2 = layers.Bidirectional(layers.LSTM(units=10, return_sequences=True, activation=\"tanh\"), backward_layer=layers.LSTM(units=10, return_sequences=True, go_backwards=True, activation=\"tanh\"))(bidirectional_1)\n",
    "\n",
    "# Concatenate the output of the second bidirectional LSTM layer with the input\n",
    "concatenate = layers.Concatenate()([bidirectional_2, input_layer])\n",
    "\n",
    "# Cropping1D layer\n",
    "cropping1d = layers.Cropping1D(cropping=(12, 12))(concatenate)  # Adjust the cropping as necessary\n",
    "\n",
    "# TimeDistributed layer with Dense layer inside\n",
    "time_distributed_1 = layers.TimeDistributed(layers.Dense(units=16, activation=\"relu\"))(cropping1d)\n",
    "\n",
    "# Another TimeDistributed layer with Dense layer inside\n",
    "time_distributed_2 = layers.TimeDistributed(layers.Dense(units=16, activation=\"relu\"))(time_distributed_1)\n",
    "\n",
    "# Final TimeDistributed layer with Dense layer for output\n",
    "time_distributed_3 = layers.TimeDistributed(layers.Dense(units=1, activation=\"linear\"))(time_distributed_2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=time_distributed_3)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=tf.keras.losses.MeanAbsoluteError(reduction=\"sum_over_batch_size\"),\n",
    "    metrics=['mse'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "global initial_epoch\n",
    "initial_epoch = 0\n",
    "class EpochCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global initial_epoch\n",
    "        initial_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 300\n",
    "\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data=(test_x, test_y),\n",
    "    callbacks=[tensorboard_callback, EpochCallback()],\n",
    "    batch_size=128,\n",
    "    epochs=initial_epoch + train_epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "\n",
    "if mode == \"full\":\n",
    "    model.save(f\"{model_dir}/model.keras\")\n",
    "\n",
    "    spec = (tf.TensorSpec((None, segment_size, note_size), tf.float32),)\n",
    "    model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=None, output_path=f\"{model_dir}/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_samples(leaderboards, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for leaderboard_id, leaderboard_replays in test_data:\n",
    "#     try:\n",
    "#         curr, score = preprocess_leaderboard_replays(leaderboard_replays)\n",
    "\n",
    "#         _predictions = model.predict(np.array(curr))\n",
    "\n",
    "#         real_sum = 0\n",
    "#         for prediction in score:\n",
    "#             real_sum += prediction[0]\n",
    "\n",
    "#         real_avg = real_sum / len(score)\n",
    "#         real_percentage_score = (100 + real_avg * 15) / 115\n",
    "\n",
    "#         prediction_sum = 0\n",
    "#         for prediction in _predictions:\n",
    "#             prediction_sum += prediction[0]\n",
    "\n",
    "#         avg = prediction_sum / len(_predictions)\n",
    "#         percentage_score = (100 + avg[0] * 15) / 115\n",
    "\n",
    "#         predictions.append(\n",
    "#             [\n",
    "#                 f\"https://beatleader.xyz/leaderboard/global/{leaderboard_id}\",\n",
    "#                 round(percentage_score, 5),\n",
    "#                 round(real_percentage_score, 5),\n",
    "#                 abs(round(real_percentage_score - percentage_score, 5)),\n",
    "#             ]\n",
    "#         )\n",
    "#     except KeyboardInterrupt:\n",
    "#         raise\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         continue\n",
    "# with open(f\"{model_dir}/predictions.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     header = [\"LeaderboardId\", \"Prediction\", \"Expected\", \"Difference\"]\n",
    "#     writer.writerow(header)\n",
    "\n",
    "#     for prediction in predictions:\n",
    "#         writer.writerow(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
